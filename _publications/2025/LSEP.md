---
title:          "No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models"
date:           2025-09-27 00:00:45 +0800
selected:       false
pub:            "arXiv preprint"
pub_date:       "2025"
abstract: >-
  In this work, we present a strategy to improve training efficiency and feature quality in large-scale diffusion models. Our method, <strong>LSEP</strong> (Linear SEParability), regularizes training by promoting
  the linear separability of intermediate representations, eliminating the need for external pretrained encoders or alignment-based approaches. By incorporating linear probing directly into the learning process,
  LSEP enhances both representation quality and generation. Applied to flow-based transformer architectures such as SiTs, LSEP achieves improved efficiency and generation quality, reaching an FID of 1.46 on the 256 Ã— 256 ImageNet dataset.
cover:          /assets/pub_cover/LSEP_thumbnail.jpg
authors:
  - Junno Yun
  - Yasar Utku Alcalar
  - Mehmet Akcakaya
links:
  Paper: https://arxiv.org/abs/2509.21565
---
